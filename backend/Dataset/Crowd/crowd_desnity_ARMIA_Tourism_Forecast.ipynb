{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5a3e116",
   "metadata": {},
   "source": [
    "# ARIMA\n",
    "- Produces Crowd Predicitions based on weather and user selected location"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd456dd",
   "metadata": {},
   "source": [
    "### Load the Libaries"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 9,
=======
   "execution_count": 5,
>>>>>>> staging
=======
   "execution_count": 2,
>>>>>>> staging
   "id": "1ebb45c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sea\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, root_mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler\n",
    "from pmdarima import AutoARIMA,auto_arima\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pickle\n",
    "import os\n",
    "from datetime import datetime,timedelta,date\n",
    "import holidays as hl\n",
    "\n",
    "import openmeteo_requests\n",
    "import requests_cache\n",
    "from retry_requests import retry\n",
    "str_trim_date = pd.to_datetime('2021-01-01').to_datetime64()# The start of the dataset\n",
    "end_trim_date = pd.to_datetime('2025-12-31').to_datetime64()# The end of the dataset, shouldn't assume both actual end at this date for each location"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e0fcfb",
   "metadata": {},
   "source": [
    "### Load the data set ensure both the dataframe date range and date are in correct format for ARIMA model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "551ce9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Auck_peds = pd.read_csv(\"data_weather/Final/Auckland_Pedestrian_daily.csv\")\n",
    "Dub_peds = pd.read_csv(\"data_weather/Final/Dublin_Pedestrian_daily.csv\")\n",
    "\n",
    "df = pd.concat([Auck_peds, Dub_peds],ignore_index=True)\n",
    "\n",
    "df['Date'] = df['Date'].apply(lambda x: pd.to_datetime(x).to_datetime64())\n",
    "df = df.sort_values(['Location_ID','Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b6258390",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['2021-01-01T00:00:00.000000000', '2021-01-02T00:00:00.000000000',\n",
       "        '2021-01-03T00:00:00.000000000', ...,\n",
       "        '2025-12-29T00:00:00.000000000', '2025-12-30T00:00:00.000000000',\n",
       "        '2025-12-31T00:00:00.000000000'], dtype='datetime64[ns]')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[df['Date'].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f310aff6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([numpy.datetime64('2025-12-31T00:00:00.000000000')],\n",
       " [numpy.datetime64('2021-01-01T00:00:00.000000000')])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[end_trim_date],[str_trim_date]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e120d01",
   "metadata": {},
   "source": [
    "### Main ARIMA model\n",
    "- Model creation\n",
    "- Data splitting\n",
    "- Fitting model\n",
    "- Creates pickel files for each location\n",
    "    - Need seperate pickel files for forecasting each location \n",
    "- ARMIA needs to have even spacing between dates\n",
    "    if gap then a fill in needs to be done for Y values(Dep Var) & Exog(or X Ind Vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2cdc52f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IRDUB_1\n",
      "[(1826, 5), (1826,)]\n",
      "2024-12-31 00:00:00\n",
      "2025-03-30 00:00:00\n",
      "MAE : 29727.533457775684\n",
      "RMSE: 33920.8837994051\n",
      "R²  : -0.9522218701484291\n",
      "IRDUB_3\n",
      "[(1826, 5), (1826,)]\n",
      "2024-12-31 00:00:00\n",
      "2025-03-30 00:00:00\n",
      "MAE : 22485.45514220532\n",
      "RMSE: 25661.872200089394\n",
      "R²  : -1.1006789972823663\n",
      "IRDUB_4\n",
      "[(1826, 5), (1826,)]\n",
      "2024-12-31 00:00:00\n",
      "2025-03-30 00:00:00\n",
      "MAE : 26603.661096488384\n",
      "RMSE: 30911.153373521764\n",
      "R²  : -0.6212837079594891\n",
      "IRDUB_5\n",
      "[(1826, 5), (1826,)]\n",
      "2024-12-31 00:00:00\n",
      "2025-03-30 00:00:00\n",
      "MAE : 5494.530908943564\n",
      "RMSE: 6873.9828773365625\n",
      "R²  : 0.26864920080583177\n",
      "IRDUB_8\n",
      "[(1826, 5), (1826,)]\n",
      "2024-12-31 00:00:00\n",
      "2025-03-30 00:00:00\n",
      "MAE : 156512.6983646796\n",
      "RMSE: 166722.1696191833\n",
      "R²  : -4.678986933188882\n",
      "NZAUK_1\n",
      "[(1826, 5), (1826,)]\n",
      "2024-12-31 00:00:00\n",
      "2025-03-30 00:00:00\n",
      "MAE : 5805.350942499204\n",
      "RMSE: 7085.3636179820405\n",
      "R²  : 0.521310522908309\n",
      "NZAUK_5\n",
      "[(1826, 5), (1826,)]\n",
      "2024-12-31 00:00:00\n",
      "2025-03-30 00:00:00\n",
      "MAE : 20543.74602744719\n",
      "RMSE: 22626.185905700986\n",
      "R²  : -0.013747570443654489\n",
      "NZAUK_6\n",
      "[(1826, 5), (1826,)]\n",
      "2024-12-31 00:00:00\n",
      "2025-03-30 00:00:00\n",
      "MAE : 10306.830033665154\n",
      "RMSE: 11590.54202405199\n",
      "R²  : 0.08846885896144208\n",
      "NZAUK_7\n",
      "[(1826, 5), (1826,)]\n",
      "2024-12-31 00:00:00\n",
      "2025-03-30 00:00:00\n",
      "MAE : 2767.4971245964134\n",
      "RMSE: 3252.667398708566\n",
      "R²  : 0.07915404290777917\n"
     ]
    }
   ],
   "source": [
    "models = {}\n",
    "for loc in df['Location_ID'].unique():\n",
    "    print(loc)\n",
    "    sub = df[df['Location_ID'] == loc] \n",
    "    sub = sub.drop_duplicates(subset=['Date'], keep='first').sort_values('Date').set_index('Date')# Important for the ARIMA model to function \n",
    "\n",
    "    y = sub['PedsSen_Count'].asfreq('D').interpolate()\n",
    "    x = sub[['Weather_Temperature',\n",
    "             'Weather_Wind_Gust',\n",
    "             'Weather_Relative_Humidity',\n",
    "             'Weather_Precipitation',\n",
    "             'Is_Holiday']].asfreq('D').interpolate()\n",
    "\n",
    "    y = y[(y.index <= end_trim_date) & (y.index >= str_trim_date)] # will change depending on new datasets in the future\n",
    "    x = x[(x.index <= end_trim_date) & (x.index >= str_trim_date)] # will change depending on new datasets in the future \n",
    "    print([x.shape,y.shape])\n",
    "\n",
    "    split = int(len(y) * 0.8) # keep chrno order \n",
    "\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    y_train = y.iloc[:split]\n",
    "    y_test  = y.iloc[split:]\n",
    "\n",
    "    x_train = scaler.fit_transform(x.iloc[:split])\n",
    "    x_test  = scaler.transform(x.iloc[split:])\n",
    "    # x_train = x.iloc[:split]\n",
    "    # x_test  = x.iloc[split:]\n",
    "\n",
    "    # # ARIMA parameters\n",
    "    stepwise = auto_arima(y=y_train, # Dep\n",
    "                      x=x_train, #Inp\n",
    "                      seasonal=True,\n",
    "                      m=7, # 7 day pattern\n",
    "                      trace=False,\n",
    "                      error_action='ignore',\n",
    "                      suppress_warnings=True,\n",
    "                      )\n",
    "    \n",
    "    # # SARIMAx model fitting\n",
    "    model = SARIMAX(endog=y_train, # Dep\n",
    "                    exog=x_train, # Indep\n",
    "                    order=stepwise.order, seasonal_order=stepwise.seasonal_order,\n",
    "                    enforce_stationarity=False, # Variance and trends aren't constant set to false\n",
    "                    enforce_invertibility=False)\n",
    "    results = model.fit(disp=False)\n",
    "\n",
    "    day = 90 # 3 months\n",
    "    yt = y_test[:day]\n",
    "    start_date = yt.index[0] # using the date index \n",
    "    end_date   = yt.index[-1]\n",
    "    print(start_date)\n",
    "    print(end_date)\n",
    "\n",
    "    y_pred = results.predict(\n",
    "        start=start_date,\n",
    "        end=end_date,\n",
    "        exog=x_test[:day]\n",
    "    )\n",
    "\n",
    "    mae  = mean_absolute_error(yt, y_pred)\n",
    "    rmse = root_mean_squared_error(yt, y_pred)\n",
    "    r2   = r2_score(yt, y_pred)\n",
    "\n",
    "    print(\"MAE :\", mae)\n",
    "    print(\"RMSE:\", rmse)\n",
    "    print(\"R²  :\", r2)\n",
    "\n",
    "    models[f'{loc}'] = results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc529969",
   "metadata": {},
   "source": [
    "### Save model pickel files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ba01ca9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"arima_models\", exist_ok=True) \n",
    "for loc,results in models.items():\n",
    "    # Save model\n",
    "    model_path = f\"arima_models/{loc}_arima.pkl\"\n",
    "    with open(model_path, \"wb\") as f:\n",
    "        pickle.dump(results, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9395d4",
   "metadata": {},
   "source": [
    "#### Use a test case"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 10,
=======
   "execution_count": 8,
>>>>>>> staging
=======
   "execution_count": 3,
>>>>>>> staging
   "id": "855471b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the Open-Meteo API client with cache and retry on error # <--- this is from Open Meteo Api Docs\n",
    "cache_session = requests_cache.CachedSession('.amriacache', expire_after = 3600)\n",
    "retry_session = retry(cache_session, retries = 5, backoff_factor = 0.2)\n",
    "openmeteo = openmeteo_requests.Client(session = retry_session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07c57526",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Weather_Requester(lat:float,long:float) -> pd.DataFrame:\n",
    "    url = \"https://archive-api.open-meteo.com/v1/archive\" # Histroical Data\n",
    "    params = {\n",
    "        \"latitude\": lat,\n",
    "        \"longitude\": long,\n",
    "        \"start_date\": '2026-01-01',\n",
    "        \"end_date\": (date.today()-timedelta(days=1)).strftime('%Y-%m-%d'),\n",
    "        \"daily\": [\"temperature_2m_mean\", \"wind_gusts_10m_mean\", \"relative_humidity_2m_mean\", \"precipitation_sum\"],\n",
    "        \"timezone\": \"auto\",\n",
    "    }\n",
    "    responses = openmeteo.weather_api(url, params=params)\n",
    "    # Basically getting the data for the beginning of the trim point of Sep 30 2025 of the dataset to 1 day - current day   \n",
    "    dly = responses[0].Daily()\n",
    "\n",
    "    T1 = dly.Variables(0).ValuesAsNumpy() # Np array's \n",
    "    W1 = dly.Variables(1).ValuesAsNumpy()\n",
    "    R1 = dly.Variables(2).ValuesAsNumpy()\n",
    "    P1 = dly.Variables(3).ValuesAsNumpy()\n",
    "\n",
    "    url = \"https://seasonal-api.open-meteo.com/v1/seasonal\" # Future Data\n",
    "    params = {\n",
    "        \"latitude\": lat,\n",
    "        \"longitude\": long,\n",
    "        \"forecast_days\": 180,\n",
    "        \"timezone\": \"auto\",\n",
    "        \"daily\": [\"temperature_2m_mean\", \"wind_speed_10m_mean\", \"relative_humidity_2m_mean\", \"precipitation_sum\"]\n",
    "    }\n",
    "    responses = openmeteo.weather_api(url, params=params)\n",
    "    dly = responses[0].Daily()\n",
    "\n",
    "    T2 = dly.Variables(0).ValuesAsNumpy()\n",
    "    W2 = dly.Variables(1).ValuesAsNumpy()\n",
    "    R2 = dly.Variables(2).ValuesAsNumpy()\n",
    "    P2 = dly.Variables(3).ValuesAsNumpy()\n",
    "\n",
    "    T = np.concatenate((T1,T2))\n",
    "    W = np.concatenate((W1,W2))\n",
    "    P = np.concatenate((P1,P2))\n",
    "    R = np.concatenate((R1,R2))\n",
    "    \n",
    "    # Build the final indep array, holiday and time will be added later\n",
    "    vstk = pd.DataFrame(data = np.vstack((T,W,P,R)).T,\n",
    "                        columns=['Weather_Temperature',\n",
    "                                 'Weather_Wind_Gust',\n",
    "                                 'Weather_Relative_Humidity',\n",
    "                                 'Weather_Precipitation'])\n",
    "\n",
    "    return vstk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2556a44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Holidayer(df:pd.DataFrame,CCode:str) -> pd.DataFrame:\n",
    "    # Uses country code and each data to find holiday or not\n",
    "    df['Is_Holiday'] = df['Date'].apply(lambda x: 1 if hl.country_holidays(country=CCode).get(x) != None else 0)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ba835d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-02\n",
      "0      2026-01-01\n",
      "1      2026-01-02\n",
      "2      2026-01-03\n",
      "3      2026-01-04\n",
      "4      2026-01-05\n",
      "          ...    \n",
      "210    2026-07-30\n",
      "211    2026-07-31\n",
      "212    2026-08-01\n",
      "213    2026-08-02\n",
      "214    2026-08-03\n",
      "Name: Date, Length: 215, dtype: object\n",
      "            predicted_mean\n",
      "2024-12-31   -28659.076670\n",
      "2025-01-01   -24303.932708\n",
      "2025-01-02   -26967.874892\n",
      "2025-01-03   -11391.730095\n",
      "2025-01-04   -22382.754127\n",
      "...                    ...\n",
      "2025-07-29    22915.286394\n",
      "2025-07-30    23016.656063\n",
      "2025-07-31    32410.201296\n",
      "2025-08-01    32511.582624\n",
      "2025-08-02    22919.614327\n",
      "\n",
      "[215 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "loc = \"NZAUK_1\" # This was a location to be displayed to user\n",
    "with open(f\"arima_models/{loc}_arima.pkl\", \"rb\") as f:\n",
    "    model = pickle.load(f) # grab right pickel file\n",
    "\n",
    "d = datetime(2026,4,23).date()# User specfiies a date -- test\n",
    "w = Weather_Requester(-36.8485,174.7633) # Grab weather from past and for future\n",
    "w.insert(4,'Is_Holiday',0)# Inserting these columns to match indep input\n",
    "w.insert(0,'Date',range(len(w))) # Use range to fill in date indexing numbers \n",
    "# Add in the date range from trim point 2026-01-01\n",
    "w['Date'] = w['Date'].apply(lambda x: datetime(2026,1,1).date() + timedelta(days=x))\n",
    "h = Holidayer(w,'IE') # Add in the holiday data\n",
    "h = h.set_index('Date').asfreq('D').interpolate(method='linear') # numeric only\n",
    "# Send to predict next set of days\n",
    "pred_mean = pd.DataFrame(model.get_forecast(exog=h,steps=len(h)).predicted_mean)\n",
    "print(pred_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "80c2abbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2024-12-31 00:00:00')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_meancp = pred_mean.copy()\n",
    "idx = pred_meancp.index[:1][0] # deaaling with timestamps\n",
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7a0366f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2026-04-23 00:00:00')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = pd.Timestamp(d) # convert user specified date\n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "952e36a4",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "Timestamp('2026-04-23 00:00:00')",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:609\u001b[39m, in \u001b[36mpandas._libs.index.DatetimeEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:2606\u001b[39m, in \u001b[36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:2630\u001b[39m, in \u001b[36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 1776902400000000000",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3804\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3805\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3806\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:577\u001b[39m, in \u001b[36mpandas._libs.index.DatetimeEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:611\u001b[39m, in \u001b[36mpandas._libs.index.DatetimeEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: Timestamp('2026-04-23 00:00:00')",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pandas\\core\\indexes\\datetimes.py:630\u001b[39m, in \u001b[36mDatetimeIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m    629\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m630\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mIndex\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    631\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3811\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3814\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3815\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3816\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n",
      "\u001b[31mKeyError\u001b[39m: Timestamp('2026-04-23 00:00:00')",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# how to get the forecasted crowd number at a date for a lcoation\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m [\u001b[43mpred_meancp\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mpredicted_mean\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mf\u001b[49m\u001b[43m]\u001b[49m] \n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pandas\\core\\indexing.py:1191\u001b[39m, in \u001b[36m_LocationIndexer.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   1189\u001b[39m maybe_callable = com.apply_if_callable(key, \u001b[38;5;28mself\u001b[39m.obj)\n\u001b[32m   1190\u001b[39m maybe_callable = \u001b[38;5;28mself\u001b[39m._check_deprecated_callable_usage(key, maybe_callable)\n\u001b[32m-> \u001b[39m\u001b[32m1191\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_getitem_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaybe_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pandas\\core\\indexing.py:1431\u001b[39m, in \u001b[36m_LocIndexer._getitem_axis\u001b[39m\u001b[34m(self, key, axis)\u001b[39m\n\u001b[32m   1429\u001b[39m \u001b[38;5;66;03m# fall thru to straight lookup\u001b[39;00m\n\u001b[32m   1430\u001b[39m \u001b[38;5;28mself\u001b[39m._validate_key(key, axis)\n\u001b[32m-> \u001b[39m\u001b[32m1431\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_label\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pandas\\core\\indexing.py:1381\u001b[39m, in \u001b[36m_LocIndexer._get_label\u001b[39m\u001b[34m(self, label, axis)\u001b[39m\n\u001b[32m   1379\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_get_label\u001b[39m(\u001b[38;5;28mself\u001b[39m, label, axis: AxisInt):\n\u001b[32m   1380\u001b[39m     \u001b[38;5;66;03m# GH#5567 this will fail if the label is not present in the axis.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1381\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mxs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pandas\\core\\generic.py:4301\u001b[39m, in \u001b[36mNDFrame.xs\u001b[39m\u001b[34m(self, key, axis, level, drop_level)\u001b[39m\n\u001b[32m   4299\u001b[39m             new_index = index[loc]\n\u001b[32m   4300\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m4301\u001b[39m     loc = \u001b[43mindex\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4303\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(loc, np.ndarray):\n\u001b[32m   4304\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m loc.dtype == np.bool_:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pandas\\core\\indexes\\datetimes.py:632\u001b[39m, in \u001b[36mDatetimeIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m    630\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m Index.get_loc(\u001b[38;5;28mself\u001b[39m, key)\n\u001b[32m    631\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m--> \u001b[39m\u001b[32m632\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(orig_key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n",
      "\u001b[31mKeyError\u001b[39m: Timestamp('2026-04-23 00:00:00')"
     ]
    }
   ],
   "source": [
    "# how to get the forecasted crowd number at a date for a lcoation\n",
    "[pred_meancp['predicted_mean'].loc[f]] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "c1870f60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Timestamp('2025-10-30 00:00:00'), 8673.199239607291)\n",
      "(Timestamp('2025-10-31 00:00:00'), 9248.587278072411)\n",
      "(Timestamp('2025-11-01 00:00:00'), 8034.03073101135)\n",
      "(Timestamp('2025-11-02 00:00:00'), 6457.493610934678)\n",
      "(Timestamp('2025-11-03 00:00:00'), 8026.887653059958)\n",
      "(Timestamp('2025-11-04 00:00:00'), 8478.44526924403)\n",
      "(Timestamp('2025-11-05 00:00:00'), 8805.872951263025)\n",
      "(Timestamp('2025-11-06 00:00:00'), 8476.157840438196)\n",
      "(Timestamp('2025-11-07 00:00:00'), 8853.743776221445)\n",
      "(Timestamp('2025-11-08 00:00:00'), 8081.045105048558)\n",
      "(Timestamp('2025-11-09 00:00:00'), 6404.394135615088)\n",
      "(Timestamp('2025-11-10 00:00:00'), 8244.583391882095)\n",
      "(Timestamp('2025-11-11 00:00:00'), 8684.17733286873)\n",
      "(Timestamp('2025-11-12 00:00:00'), 9069.288528674771)\n",
      "(Timestamp('2025-11-13 00:00:00'), 7123.70280773749)\n",
      "(Timestamp('2025-11-14 00:00:00'), 8931.54895080841)\n",
      "(Timestamp('2025-11-15 00:00:00'), 8230.966023380839)\n",
      "(Timestamp('2025-11-16 00:00:00'), 6624.710422696017)\n",
      "(Timestamp('2025-11-17 00:00:00'), 8246.09476627702)\n",
      "(Timestamp('2025-11-18 00:00:00'), 8788.398437320306)\n",
      "(Timestamp('2025-11-19 00:00:00'), 8913.049287152593)\n",
      "(Timestamp('2025-11-20 00:00:00'), 8620.019551116264)\n",
      "(Timestamp('2025-11-21 00:00:00'), 9133.125541132034)\n",
      "(Timestamp('2025-11-22 00:00:00'), 8306.95492814989)\n",
      "(Timestamp('2025-11-23 00:00:00'), 6676.747894060627)\n",
      "(Timestamp('2025-11-24 00:00:00'), 8362.869468897085)\n",
      "(Timestamp('2025-11-25 00:00:00'), 8924.840616257468)\n",
      "(Timestamp('2025-11-26 00:00:00'), 9323.367182792492)\n",
      "(Timestamp('2025-11-27 00:00:00'), 9103.147885620243)\n",
      "(Timestamp('2025-11-28 00:00:00'), 9381.254291327246)\n",
      "(Timestamp('2025-11-29 00:00:00'), 8784.321120894465)\n",
      "(Timestamp('2025-11-30 00:00:00'), 7013.498993433363)\n",
      "(Timestamp('2025-12-01 00:00:00'), 8922.380692774708)\n",
      "(Timestamp('2025-12-02 00:00:00'), 8830.58105016574)\n",
      "(Timestamp('2025-12-03 00:00:00'), 8869.585985271793)\n",
      "(Timestamp('2025-12-04 00:00:00'), 8727.74043650147)\n",
      "(Timestamp('2025-12-05 00:00:00'), 9246.308312391968)\n",
      "(Timestamp('2025-12-06 00:00:00'), 8534.496604444947)\n",
      "(Timestamp('2025-12-07 00:00:00'), 6777.1529287959875)\n",
      "(Timestamp('2025-12-08 00:00:00'), 8797.74782692913)\n",
      "(Timestamp('2025-12-09 00:00:00'), 9110.491523090801)\n"
     ]
    }
   ],
   "source": [
    "print(*pred_meancp['predicted_mean'].loc[f - timedelta(days=30):f + timedelta(days=10)].items(),sep='\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
